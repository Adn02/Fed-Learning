{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e81ccc-bcc7-4644-911f-4f6f4fef9b32",
   "metadata": {},
   "source": [
    "<h1>The purpose of this notebook is to mimic the FedAvg Algorithm used in <i>Communication-Efficient Learning of Deep Networks from Decentralized Data</i>, produce similar results, and gain coding experience in Federated Learning concepts</h1> For HW, compare IID vs non IID, and implement round robin style scheduling of clients compared to the \"random\" scheduling. If no change is seen then change the parameters to show the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41378390-df78-4bf9-a76b-43749e984635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Global Dependencies\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Import Helper Libaries\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd4e94-9672-4540-99fa-b6362ed1fabe",
   "metadata": {},
   "source": [
    "<h2>CNN Model Declaration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42140649-bfe2-4b09-94b4-af2ed5f85f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=args.num_dimensions, out_channels=32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, args.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae0be2-ae10-4ca1-bca7-15001291d51c",
   "metadata": {},
   "source": [
    "<h2>Local Model Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee6591-5dcc-43da-b70f-48b32dfea73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_update(clients, optimizer, training_loader, epochs):\n",
    "    clients.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (inputs, labels) in enumerate(training_loader):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = clients(inputs)\n",
    "            loss = nn.CrossEntropyLoss()(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d5b39-4b0d-4dd1-b328-b6e3de8a6e11",
   "metadata": {},
   "source": [
    "<h2>Global Aggregator</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f9b57-59f8-4e51-b6f0-0764e8b14452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_aggregate(global_model, client_models):\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k] for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b49b5-990b-4555-8bb8-869eb940c037",
   "metadata": {},
   "source": [
    "<h2>Model Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18ab62-95b1-4c67-8898-63c2d9eaf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(global_model, validation_loader):\n",
    "    global_model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            output = global_model(inputs)\n",
    "            loss += nn.CrossEntropyLoss()(output, labels).item()  # Using the criterion\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    loss /= len(validation_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8123a5d-6cbc-4ab4-a4eb-91a5ef93f988",
   "metadata": {},
   "source": [
    "<h2>Federated Averaging Algorithm</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd4e88-1f90-46b7-9031-8275e928ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedAvg(local_ws, clients):\n",
    "    avg_w = {}\n",
    "    for k in local_ws[0].keys():\n",
    "        sum_w = torch.zeros_like(local_ws[0][k])\n",
    "        for i in range(len(local_ws)):\n",
    "            sum_w += torch.mul(local_ws[i][k], clients[i])\n",
    "        avg_w[k] = torch.div(sum_w, sum(clients))\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb069d-0da7-4b70-8677-2f91acec115a",
   "metadata": {},
   "source": [
    "<h2>Federated Training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0745d-63e2-4913-b616-09d8a32910df",
   "metadata": {},
   "source": [
    "<h3>Training using Random Scheduling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a4fdfc-ded9-40db-b8be-57f8941cc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training(global_model, args):\n",
    "    clients = [CNN(args=args).to(args.device) for _ in range(args.total_clients)]\n",
    "    for models in clients:\n",
    "        models.load_state_dict(global_model.state_dict())\n",
    "    \n",
    "    opt = [optim.SGD(models.parameters(), lr=args.lr) for models in clients]\n",
    "\n",
    "    round_losses, round_accuracies = [], []\n",
    "\n",
    "    global_start_time = time.time()\n",
    "    for round in range(args.total_rounds):\n",
    "        start_time = time.time()\n",
    "        clients_idx = np.random.permutation(args.total_clients)[:args.clients_per_round]\n",
    "    \n",
    "        client_losses = 0\n",
    "        selected_models = []\n",
    "\n",
    "        for i in range(args.clients_per_round):\n",
    "            clients[clients_idx[i]].load_state_dict(global_model.state_dict())\n",
    "            client_losses += client_update(clients[clients_idx[i]], opt[clients_idx[i]], training_loader[clients_idx[i]], args.local_epochs)\n",
    "            selected_models.append(clients[clients_idx[i]])\n",
    "        \n",
    "        global_aggregate(global_model, selected_models)\n",
    "    \n",
    "        avg_loss = client_losses / args.clients_per_round\n",
    "        round_loss , round_accuracy = model_evaluation(global_model, validation_loader)\n",
    "\n",
    "        round_losses.append(round_loss)\n",
    "        round_accuracies.append(round_accuracy)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        round_time = end_time - start_time\n",
    "    \n",
    "        if (round % 50) == 0:\n",
    "            rounds_end_time = time.time()\n",
    "            rounds_time = rounds_end_time - global_start_time\n",
    "            print('Round {:3d}, Time (secs) {:.2f}: Average loss {:.4f}, Accuracy {:.4f}'.format(round + 1, rounds_time, round_loss, round_accuracy))\n",
    "    return round_losses, round_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932137cf-fa6d-41fd-abd5-6d06817eebd5",
   "metadata": {},
   "source": [
    "<h3>Training using Age Based Scheduling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ef21a-2f35-4b12-98c9-256c96501bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_selection(clients, global_AOU, clients_AOU):\n",
    "    idx_to_sort = np.where(clients_AOU != global_AOU)[0]\n",
    "    clients_AOU_sorted = np.argsort(clients_AOU[idx_to_sort])\n",
    "    \n",
    "    selected_clients_idx = idx_to_sort[clients_AOU_sorted[:10]]\n",
    "\n",
    "    return selected_clients_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72cf797-2b05-414b-95a6-a8c289c3c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduled_training(global_model, args):\n",
    "    clients = [CNN(args=args).to(args.device) for _ in range(args.total_clients)]\n",
    "    for models in clients:\n",
    "        models.load_state_dict(global_model.state_dict())\n",
    "    \n",
    "    opt = [optim.SGD(models.parameters(), lr=args.lr) for models in clients]\n",
    "    global_AOU = 0\n",
    "    clients_AOU = np.zeros(args.total_clients)\n",
    "    round_losses, round_accuracies = [], []\n",
    "\n",
    "    global_start_time = time.time()\n",
    "    for round in range(args.total_rounds):\n",
    "        round_start_time = time.time()\n",
    "\n",
    "        if global_AOU == 0:\n",
    "            clients_idx = (np.random.permutation(args.total_clients)[:args.clients_per_round])\n",
    "        else:\n",
    "            clients_idx = client_selection(clients, global_AOU, clients_AOU)\n",
    "\n",
    "        global_AOU += 1\n",
    "        client_losses = 0      \n",
    "        selected_models = []\n",
    "        \n",
    "        for i in range(args.clients_per_round):\n",
    "            clients[clients_idx[i]].load_state_dict(global_model.state_dict())\n",
    "            client_losses += client_update(clients[clients_idx[i]], opt[clients_idx[i]], training_loader[clients_idx[i]], args.local_epochs)\n",
    "            selected_models.append(clients[clients_idx[i]])\n",
    "            client_AOU[clients_idx[i]] = global_AOU\n",
    "        \n",
    "        global_aggregate(global_model, selected_models)\n",
    "    \n",
    "        avg_loss = client_losses / args.clients_per_round\n",
    "        round_loss , round_accuracy = model_evaluation(global_model, validation_loader)\n",
    "\n",
    "        round_losses.append(round_loss)\n",
    "        round_accuracies.append(round_accuracy)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        round_time = end_time - start_time\n",
    "        \n",
    "        if (round % 10) == 0:\n",
    "            rounds_end_time = time.time()\n",
    "            rounds_time = rounds_end_time - global_start_time\n",
    "            print('Round {:3d}, Time (secs) {:.2f}: Average loss {:.4f}, Accuracy {:.4f}'.format(round + 1, rounds_time, round_loss, round_accuracy))\n",
    "    return round_losses, round_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950a6f7-30e7-48a1-98ac-355225b54c3d",
   "metadata": {},
   "source": [
    "<h2>Hyperparameters for IID</h2>\n",
    "The data is shuffled and then divided up across 100 clients each receiving 600 examples.\n",
    "\n",
    "Training is done using Random Scheduling and Age Based Scheduling (See random_training and scheduled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46bef3-dd48-451f-8877-c5d44cd4b540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FederatedSettings:\n",
    "    def __init__(self, device, num_classes, num_dimensions, lr, total_rounds, verbose, total_clients, clients_per_round, local_batchsize, local_epochs):\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.num_dimensions = num_dimensions\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.total_rounds = total_rounds                    \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.total_clients = total_clients\n",
    "        self.clients_per_round = clients_per_round    \n",
    "        self.local_batchsize = local_batchsize\n",
    "        self.local_epochs = local_epochs\n",
    "\n",
    "args = FederatedSettings(\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    num_dimensions = 1,                                # Input Shape\n",
    "    num_classes = 10,                                  # Output Classes\n",
    "\n",
    "    lr = 0.1,                                          # Learning Rate \n",
    "    total_rounds = 500,                                # Global Epochs or 'Communication rounds'    \n",
    "    verbose = False,\n",
    "    \n",
    "    total_clients = 100,                               # Clients participating per round (K)\n",
    "    clients_per_round = 10,                            # Fraction of Clients (C)\n",
    "    local_batchsize = 10,                              # Local Minibatch size (B)\n",
    "    local_epochs = 5,                                  # Local Epochs (E)\n",
    ")\n",
    "\n",
    "normalize = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "training_dataset = datasets.MNIST('../data', train=True, download=True, transform=normalize)\n",
    "validation_dataset = datasets.MNIST('./data', train=False, download = True, transform=normalize)\n",
    "\n",
    "data_split = torch.utils.data.random_split(training_dataset, [int(training_dataset.data.shape[0] / args.total_clients) for _ in range(args.total_clients)])\n",
    "\n",
    "training_loader = [torch.utils.data.DataLoader(x, batch_size=args.local_batchsize, shuffle=True) for x in data_split]\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=args.local_batchsize, shuffle=True)\n",
    "\n",
    "global_model_random_IID = CNN(args=args).to(args.device)\n",
    "global_model_scheduled_IID = CNN(args=args).to(args.device)\n",
    "\n",
    "print(\"Beginning Random Scheduling IID Training\")\n",
    "random_losses_IID, random_accuracies_IID = random_training(global_model_random_IID, args)\n",
    "\n",
    "print(\"\\nBeginning Age Based Scheduling IID Training\")\n",
    "scheduled_losses_IID, scheduled_accuracies_IID = scheduled_training(global_model_scheduled_IID, args)\n",
    "\n",
    "# torch.save(global_model_random_IID, \"FedAvg_Random-Schedule-IID\")\n",
    "# torch.save(global_model_scheduled_IID, \"FedAvg_AgeBased-Schedule-IID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ae80f-38f6-483c-a801-e96c63f24e1c",
   "metadata": {},
   "source": [
    "<h2>Hyperparameters for Non-IID</h2>\n",
    "The data is sorted by digit label, divided up into 200 'shards' of 300 examples, and then each client receieves 2 'shards'\n",
    "\n",
    "Training is done using Random Scheduling and Age Based Scheduling (See random_training and scheduled_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f6dfe-7a37-474a-bf51-3f45ffd92be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FederatedSettings:\n",
    "    def __init__(self, device, num_classes, num_dimensions, lr, total_rounds, verbose, total_clients, clients_per_round, local_batchsize, local_epochs):\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.num_dimensions = num_dimensions\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.total_rounds = total_rounds                    \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.total_clients = total_clients\n",
    "        self.clients_per_round = clients_per_round    \n",
    "        self.local_batchsize = local_batchsize\n",
    "        self.local_epochs = local_epochs\n",
    "\n",
    "args = FederatedSettings(\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    num_dimensions = 1,                                # Input Shape\n",
    "    num_classes = 10,                                  # Output Classes\n",
    "\n",
    "    lr = 0.1,                                          # Learning Rate \n",
    "    total_rounds = 500,                                # Global Epochs or 'Communication rounds'    \n",
    "    verbose = False,\n",
    "    \n",
    "    total_clients = 100,                               # Clients participating per round (K)\n",
    "    clients_per_round = 10,                            # Fraction of Clients (C)\n",
    "    local_batchsize = 10,                              # Local Minibatch size (B)\n",
    "    local_epochs = 5,                                  # Local Epochs (E)\n",
    ")\n",
    "\n",
    "normalize = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "training_dataset = datasets.MNIST('../data', train=True, download=True, transform=normalize)\n",
    "validation_dataset = datasets.MNIST('./data', train=False, download = True, transform=normalize)\n",
    "\n",
    "training_labels = torch.stack([training_dataset.targets == i for i in range(10)])\n",
    "training_labels_split = []\n",
    "\n",
    "for i in range(5):\n",
    "    training_labels_split += torch.split(torch.where(training_labels[(2 * i):(2 * (i + 1))].sum(0))[0], int(len(training_dataset.data) / args.total_clients))\n",
    "training_dataset_split = [torch.utils.data.Subset(training_dataset, labels) for labels in training_labels_split]\n",
    "training_loader = [torch.utils.data.DataLoader(x, batch_size=args.local_batchsize, shuffle=True) for x in training_dataset_split]\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=args.local_batchsize, shuffle=True)\n",
    "\n",
    "global_model_random_nonIID = CNN(args=args).to(args.device)\n",
    "global_model_scheduled_nonIID = CNN(args=args).to(args.device)\n",
    "\n",
    "print(\"Beginning Random Scheduling nonIID Training\")\n",
    "random_losses_nonIID, random_accuracies_nonIID = random_training(global_model_random_nonIID, args)\n",
    "\n",
    "print(\"Beginning Age Based Scheduling nonIID Training\")\n",
    "scheduled_losses_nonIID, scheduled_accuracies_nonIID = scheduled_training(global_model_scheduled_nonIID, args)\n",
    "\n",
    "# torch.save(global_model_random_nonIID, \"FedAvg_Random-Schedule-nonIID\")\n",
    "# torch.save(global_model_scheduled_nonIID, \"FedAvg_AgeBased-Schedule-nonIID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a5be7-0d5f-4a5f-bb66-3f6d90f0f40f",
   "metadata": {},
   "source": [
    "<h2>Global Model Complexity Comparisons</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c8424-d84b-46d3-9113-df79df2d5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random_IID_stats = summary(global_model_random_IID, input_size=(1, 28, 28), col_width=16, col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"], row_settings=[\"var_names\"])\n",
    "model_scheduled_IID_stats = summary(global_model_scheduled_IID, input_size=(1, 28, 28), col_width=16, col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"], row_settings=[\"var_names\"])\n",
    "\n",
    "model_random_nonIID_stats = summary(global_model_random_nonIID, input_size=(1, 28, 28), col_width=16, col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"], row_settings=[\"var_names\"])\n",
    "model_scheduled_nonIID_stats = summary(global_model_scheduled_nonIID, input_size=(1, 28, 28), col_width=16, col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"], row_settings=[\"var_names\"])\n",
    "\n",
    "\n",
    "print(\"\\t\\t\\t\\t\\tIID Model Comparisons\\n\")\n",
    "print(\"{:^80}\".format(\"======================================== Random IID Model ==============================================\"))\n",
    "print(model_random_IID_stats)\n",
    "print(\"{:^80}\".format(\"\\n======================================== Scheduled IID Model ===========================================\"))\n",
    "print(model_scheduled_IID_stats)\n",
    "\n",
    "print(\"\\n\\t\\t\\t\\t\\tNon-IID Model Comparisons\\n\")\n",
    "print(\"{:^80}\".format(\"======================================== Random Non-IID Model ==========================================\"))\n",
    "print(model_random_nonIID_stats)\n",
    "print(\"{:^80}\".format(\"\\n======================================== Scheduled Non-IID Model =======================================\"))\n",
    "print(model_scheduled_nonIID_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ee349-f106-44eb-8a9a-9d0e88b2cdf6",
   "metadata": {},
   "source": [
    "<h2>Model Training/Inferencing Experience Comparison</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c0d1c-8080-40ba-abbf-aace1bf9106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'=================================== Final Accuracies per Model ====================================')\n",
    "print(f'Random IID     Model Accuracy: {random_accuracies_IID[-1]},\\t\\t Age Based Scheduled IID     Model Accuracy: {scheduled_accuracies_IID[-1]}')\n",
    "print(f'Random Non-IID Model Accuracy: {random_accuracies_nonIID[-1]},\\t\\t Age Based Scheduled Non-IID Model Accuracy: {scheduled_accuracies_nonIID[-1]}')\n",
    "print(f'===================================================================================================')\n",
    "\n",
    "epochs_range = range(1, args.total_rounds + 1)\n",
    "\n",
    "# Plot Global Training Loss for IID\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, random_losses_IID, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.plot(epochs_range, scheduled_losses_IID, color='blue', linestyle=\"dotted\", label=\"Age based Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.legend(loc='upper right')  \n",
    "plt.title('MNIST CNN IID Loss Curve, (B=10, E=5)')\n",
    "\n",
    "# Plot Global Validation Accuracy for IID\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, random_accuracies_IID, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.plot(epochs_range, scheduled_accuracies_IID, color='blue', linestyle=\"dotted\", label=\"Age based Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.legend(loc='lower right') \n",
    "plt.title('MNIST CNN IID Accuracy Curve, (B=10, E=5)')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('iid_results.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot Global Training Loss for nonIID\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, random_losses_nonIID, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.plot(epochs_range, scheduled_losses_nonIID, color='blue', linestyle = \"dotted\", label=\"Age based Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.legend(loc='upper right')  \n",
    "plt.title('MNIST CNN Non-IID Loss Curve, (B=10, E=5)')\n",
    "\n",
    "# Plot Global Validation Accuracy for nonIID\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, random_accuracies_nonIID, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.plot(epochs_range, scheduled_accuracies_nonIID, color='blue', linestyle=\"dotted\", label=\"Age based Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.legend(loc='lower right') \n",
    "plt.title('MNIST CNN Non-IID Accuracy Curve, (B=10, E=5)')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('non_iid_results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b943c-d300-4218-bdc0-1212bde9000b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
