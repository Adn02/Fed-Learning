{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e81ccc-bcc7-4644-911f-4f6f4fef9b32",
   "metadata": {},
   "source": [
    "<h1>The purpose of this notebook is to mimic the FedAvg Algorithm used in <i>Communication-Efficient Learning of Deep Networks from Decentralized Data</i>, produce similar results, and gain coding experience in Federated Learning concepts</h1> For HW, compare IID vs non IDD, and implement round robin style scheduling of clients compared to the \"random\" scheduling. If no change is seen then change the parameters to show the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41378390-df78-4bf9-a76b-43749e984635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Global Dependencies\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Import Helper Libaries\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3b6a5-db84-482c-bc96-6ba664c66efb",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349fbf8-3b04-4014-8b25-4e50b46e7f09",
   "metadata": {},
   "source": [
    "<h3>Decentralize Dataset Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588e4341-5fb8-4513-9366-825e900ac048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecentralizeDataset(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, label\n",
    "        \n",
    "normalize = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "training_dataset = datasets.MNIST('../data/mnist/', train=True, download=True, transform=normalize)\n",
    "validation_dataset = datasets.MNIST('../data/mnist/', train=False, download=True, transform=normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a7f55-47ea-4981-b260-e9d6bf438cba",
   "metadata": {},
   "source": [
    "<h3>IID Data</h3>\n",
    "The data is shuffled and then divided up across 100 clients each receiving 600 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f62ea2-8410-4d74-b5f8-4c16e6c978e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IID(dataset, num_clients):\n",
    "    dict_clients = {}\n",
    "    # list of all indices in the dataset\n",
    "    idxs = list(range(len(dataset)))\n",
    "    # 600 data samples per client\n",
    "    data_per_client = len(dataset) // num_clients \n",
    "    \n",
    "    for i in range(num_clients):\n",
    "        # Randomly select a subset of indices for the current client\n",
    "        client_idxs = np.random.choice(idxs, size=data_per_client, replace=False)\n",
    "        # Add the selected indices to the dictionary for the current client\n",
    "        dict_clients[i] = set(client_idxs)\n",
    "        # Remove the selected indices from the list of available indices\n",
    "        idxs = list(set(idxs) - set(client_idxs)) \n",
    "    return dict_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22406a9-87eb-48f3-9a96-d1110c207b5d",
   "metadata": {},
   "source": [
    "<h3>Non-IID Data</h3>\n",
    "The data is sorted by digit label, divided up into 200 'shards' of 300 examples, and then each client receieves 2 'shards'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bff095c-5e9a-4286-b0cd-0bf40ad21b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonIID(dataset, num_clients):\n",
    "    dict_clients = {}\n",
    "    # List of all indices in the dataset\n",
    "    idxs = list(range(len(dataset)))\n",
    "    # 600 data samples per client\n",
    "    data_per_client = len(dataset) // num_clients\n",
    "    # Sort the dataset by label\n",
    "    sorted_idxs = sorted(idxs, key=lambda i: dataset.targets[i])\n",
    "    # Divide the sorted dataset into 200 shards of size 300\n",
    "    shards = [sorted_idxs[i:i+300] for i in range(0, len(sorted_idxs), 300)]\n",
    "    # Assign 2 shards to each client\n",
    "    shards_per_client = 2\n",
    "    for i in range(num_clients):\n",
    "        # Randomly select 2 shards for the current client\n",
    "        client_shards = np.random.choice(len(shards), size=shards_per_client, replace=False)\n",
    "        client_idxs = []\n",
    "        # Gather indices from selected shards\n",
    "        for shard_idx in client_shards:\n",
    "            client_idxs.extend(shards[shard_idx])\n",
    "        # Add the selected indices to the dictionary for the current client\n",
    "        dict_clients[i] = set(client_idxs)\n",
    "    return dict_clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd4e94-9672-4540-99fa-b6362ed1fabe",
   "metadata": {},
   "source": [
    "<h2>CNN Model Declaration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42140649-bfe2-4b09-94b4-af2ed5f85f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=args.num_dimensions, out_channels=32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, args.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = torch.softmax(x, dim=1) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae0be2-ae10-4ca1-bca7-15001291d51c",
   "metadata": {},
   "source": [
    "<h2>Local Model Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aee6591-5dcc-43da-b70f-48b32dfea73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalUpdate(object):\n",
    "    def __init__(self, args, dataset=None, idxs=None):\n",
    "        self.args = args\n",
    "        self.train_data = DataLoader(DecentralizeDataset(dataset, idxs), batch_size=self.args.local_batchsize, shuffle=True)\n",
    "\n",
    "    def local_training(self, net):\n",
    "        net.train()\n",
    "        optimizer = torch.optim.SGD(net.parameters(), lr=self.args.lr)\n",
    "        epoch_loss = []\n",
    "        \n",
    "        for epoch in range(self.args.local_epochs):\n",
    "            batch_loss = []\n",
    "            for batch_idx, (images, labels) in enumerate(self.train_data):\n",
    "                images, labels = images.to(self.args.device), labels.to(self.args.device)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                prediction = net(images)\n",
    "                loss = self.args.loss_function(prediction, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                batch_loss.append(loss.item())\n",
    "                if (self.args.verbose and batch_idx % 10 == 0):\n",
    "                    print('Local Update Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(images), len(self.train_data), 100. * batch_idx / len(self.train_data), loss.item()))\n",
    "    \n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "        return net.state_dict(), (sum(epoch_loss)/len(epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b49b5-990b-4555-8bb8-869eb940c037",
   "metadata": {},
   "source": [
    "<h2>Model Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab18ab62-95b1-4c67-8898-63c2d9eaf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(net, dataset, args):\n",
    "    net.eval()\n",
    "                     \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    validation_loader = DataLoader(dataset, batch_size=args.global_batchsize)\n",
    "\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(validation_loader):\n",
    "            images, labels = images.to(args.device), labels.to(args.device)\n",
    "            \n",
    "            prediction = net(images)\n",
    "            loss = args.loss_function(prediction, labels)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(prediction, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    validation_loss = running_loss / len(validation_loader.dataset)\n",
    "    validation_accuracy = correct / len(validation_loader.dataset)\n",
    "\n",
    "    return validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8123a5d-6cbc-4ab4-a4eb-91a5ef93f988",
   "metadata": {},
   "source": [
    "<h2>Federated Averaging Algorithm</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67dd4e88-1f90-46b7-9031-8275e928ce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedAvg(local_ws, clients):\n",
    "    avg_w = {}\n",
    "    for k in local_ws[0].keys():\n",
    "        sum_w = torch.zeros_like(local_ws[0][k])\n",
    "        for i in range(1, len(local_ws)):\n",
    "            sum_w += torch.mul(local_ws[i][k], clients[i])\n",
    "        avg_w[k] = torch.div(sum_w, sum(clients))\n",
    "    return avg_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f91a8-8b67-4e88-a44c-2ea91f4de221",
   "metadata": {},
   "source": [
    "<h2>Global Model Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bfa48db-4b73-439f-a9ad-f19f9ec0961a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training(global_model, training_dataset, validation_dataset, dict_clients, args):\n",
    "    global_loss, global_acc = [], []\n",
    "\n",
    "    global_model.train()\n",
    "    global_w = global_model.state_dict()\n",
    "    \n",
    "    for round in range(args.total_rounds):\n",
    "        local_ws, local_losses = [], []\n",
    "        m = max(int(args.fraction_clients * args.clients_per_round), 1)\n",
    "        selected_m = np.random.choice(range(args.clients_per_round), m, replace=False)\n",
    "\n",
    "        for k in selected_m:\n",
    "            local = LocalUpdate(args=args, dataset=training_dataset, idxs=dict_clients[k])\n",
    "            w, loss = local.local_training(net=copy.deepcopy(global_model).to(args.device))\n",
    "            local_ws.append(copy.deepcopy(w))\n",
    "            local_losses.append(copy.deepcopy(loss))\n",
    "\n",
    "        # Update Global Model\n",
    "        global_w = FedAvg(local_ws, selected_m)\n",
    "        global_model.load_state_dict(global_w)\n",
    "\n",
    "        # Calculate Average Loss\n",
    "        avg_loss = sum(local_losses) / len(local_losses)\n",
    "        global_loss.append(avg_loss)\n",
    "\n",
    "        # Calculate GLobal Model Evaluation Loss & Accuracy \n",
    "        global_model.eval()\n",
    "        _, global_round_acc = model_evaluation(global_model, validation_dataset, args)\n",
    "        print('Round {:3d}, Average loss {:.4f}, Accuracy {:.4f}'.format(round + 1, avg_loss, global_round_acc))\n",
    "\n",
    "        global_acc.append(global_round_acc)\n",
    "\n",
    "    global_model.eval()\n",
    "    _, final_train_acc = model_evaluation(global_model, training_dataset, args)\n",
    "    _, final_valid_acc = model_evaluation(global_model, validation_dataset, args)\n",
    "\n",
    "    print(\"\\nFinal Training accuracy: {:.4f}\".format(final_train_acc))\n",
    "    print(\"Final Testing accuracy: {:.4f}\".format(final_valid_acc))\n",
    "    \n",
    "    return global_loss, global_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950a6f7-30e7-48a1-98ac-355225b54c3d",
   "metadata": {},
   "source": [
    "<h2>Hyperparameters for IID</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c46bef3-dd48-451f-8877-c5d44cd4b540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   1, Average loss 1.8554, Accuracy 0.9134\n",
      "Round   2, Average loss 1.5506, Accuracy 0.9501\n",
      "Round   3, Average loss 1.5164, Accuracy 0.9596\n",
      "Round   4, Average loss 1.5074, Accuracy 0.9670\n"
     ]
    }
   ],
   "source": [
    "class FederatedSettings:\n",
    "    def __init__(self, device, loss_function, num_classes, num_dimensions, lr, global_batchsize, total_rounds, verbose, clients_per_round, fraction_clients, local_batchsize, local_epochs):\n",
    "        self.device = device\n",
    "        self.loss_function = loss_function\n",
    "        self.num_classes = num_classes\n",
    "        self.num_dimensions = num_dimensions\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.global_batchsize = global_batchsize\n",
    "        self.total_rounds = total_rounds                    \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.clients_per_round = clients_per_round\n",
    "        self.fraction_clients = fraction_clients    \n",
    "        self.local_batchsize = local_batchsize\n",
    "        self.local_epochs = local_epochs\n",
    "\n",
    "args = FederatedSettings(\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    loss_function = nn.CrossEntropyLoss(),             # Objective Function\n",
    "    num_dimensions = 1,                                # Input Shape\n",
    "    num_classes = 10,                                  # Output Classes\n",
    "\n",
    "    lr = 0.1,                                          # Learning Rate \n",
    "    global_batchsize = 128,                            # Global Batch Size\n",
    "    total_rounds = 1000,                               # Global Epochs or 'Communication rounds'    \n",
    "    verbose = False,\n",
    "    \n",
    "    clients_per_round = 100,                           # Clients participating per round (K)\n",
    "    fraction_clients = 0.1,                            # Fraction of Clients (C)\n",
    "    local_batchsize = 10,                              # Local Minibatch size (B)\n",
    "    local_epochs = 5,                                 # Local Epochs (E)\n",
    ")\n",
    "\n",
    "dict_clients_IID = IID(training_dataset, args.clients_per_round)\n",
    "global_model_IID = CNN(args=args).to(args.device)\n",
    "\n",
    "global_loss_IID, global_acc_IID = training(global_model_IID, training_dataset, validation_dataset, dict_clients_IID, args)\n",
    "torch.save(global_model_IID, \"FedAvg_IID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ae80f-38f6-483c-a801-e96c63f24e1c",
   "metadata": {},
   "source": [
    "<h2>Hyperparameters for Non-IID</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f6dfe-7a37-474a-bf51-3f45ffd92be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FederatedSettings:\n",
    "    def __init__(self, device, loss_function, num_classes, num_dimensions, lr, global_batchsize, total_rounds, verbose, clients_per_round, fraction_clients, local_batchsize, local_epochs):\n",
    "        self.device = device\n",
    "        self.loss_function = loss_function\n",
    "        self.num_classes = num_classes\n",
    "        self.num_dimensions = num_dimensions\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.global_batchsize = global_batchsize\n",
    "        self.total_rounds = total_rounds                    \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.clients_per_round = clients_per_round\n",
    "        self.fraction_clients = fraction_clients    \n",
    "        self.local_batchsize = local_batchsize\n",
    "        self.local_epochs = local_epochs\n",
    "\n",
    "args = FederatedSettings(\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    loss_function = nn.CrossEntropyLoss(),             # Objective Function\n",
    "    num_dimensions = 1,                                # Input Shape\n",
    "    num_classes = 10,                                  # Output Classes\n",
    "\n",
    "    lr = 0.1,                                          # Learning Rate \n",
    "    global_batchsize = 128,                            # Global Batch Size\n",
    "    total_rounds = 1000,                               # Global Epochs or 'Communication rounds'    \n",
    "    verbose = False,\n",
    "    \n",
    "    clients_per_round = 100,                           # Clients participating per round (K)\n",
    "    fraction_clients = 0.1,                            # Fraction of Clients (C)\n",
    "    local_batchsize = 10,                              # Local Minibatch size (B)\n",
    "    local_epochs = 5,                                 # Local Epochs (E)\n",
    ")\n",
    "\n",
    "dict_clients_nonIID = nonIID(training_dataset, args.clients_per_round)\n",
    "global_model_nonIID = CNN(args=args).to(args.device)\n",
    "\n",
    "global_loss_nonIID, global_acc_nonIID = training(global_model_nonIID, training_dataset, validation_dataset, dict_clients_nonIID, args)\n",
    "torch.save(global_model_nonIID, \"FedAvg_nonIID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a5be7-0d5f-4a5f-bb66-3f6d90f0f40f",
   "metadata": {},
   "source": [
    "<h2>Global Model Complexity</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366c0d1c-8080-40ba-abbf-aace1bf9106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(global_model_IID, input_size=(128, 1, 28, 28), verbose=2)\n",
    "summary(global_model_nonIID, input_size=(128, 1, 28, 28), verbose=2)\n",
    "\n",
    "# global_model = torch.load('FedAvg_IID')\n",
    "epochs_range = range(1, args.total_rounds + 1)\n",
    "\n",
    "# Plot Global Training Loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, global_loss_IID, color='red', linestyle=\"dashed\", label=\"B = 10  E = 5\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.legend(loc='upper right')  # Move legend to bottom right\n",
    "plt.title('MNIST CNN IID')\n",
    "\n",
    "# Plot Global Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, global_acc_IID, color='red', linestyle=\"dashed\", label=\"B = 10  E = 5\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.legend(loc='lower right')  # Move legend to bottom right\n",
    "plt.title('MNIST CNN IID')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, global_loss_nonIDD, color='red', linestyle=\"dashed\", label=\"B = 10  E = 5\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.legend(loc='upper right')  # Move legend to bottom right\n",
    "plt.title('MNIST CNN Non-IID')\n",
    "\n",
    "# Plot Global Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, global_acc_nonIID, color='red', linestyle=\"dashed\", label=\"B = 10  E = 5\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.legend(loc='lower right')  # Move legend to bottom right\n",
    "plt.title('MNIST CNN Non-IID')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
