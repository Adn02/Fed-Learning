{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e81ccc-bcc7-4644-911f-4f6f4fef9b32",
   "metadata": {},
   "source": [
    "<h1>Federated Learning: Scheduler Comparison</h1>\n",
    "\n",
    "<t>This notebook compares *Random*, *Age-based*, and *Age-Of-Update OR DataShapley* (AoU) Schedulers using the MNIST and CIFAR-10 Datasets.\n",
    "\n",
    "> Two models are considered,\n",
    "> 1. A Multi-layer Perceptron comprising of two hidden layers with 64 units each, utilizing the ReLU activation function\n",
    "> 2. A Convolutional Neural Network encompassing two convolutional layers with max pooling, two fully connected layers, and a softmax output layer\n",
    "\n",
    "> Two types of data distributions were considered when using the MNIST Dataset,\n",
    ">1. IID: Data is shuffled and then divided up across 100 clients each receiving 600 examples\n",
    ">2. Non-IID: Data is sorted by digit label, divided up into 200 'shards' of 300 examples, and then each client receieves 2 'shards\n",
    "\n",
    "</t>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41378390-df78-4bf9-a76b-43749e984635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Global Dependencies\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import Helper Libaries\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "filepath = \"C:/Users/aidan_000/Desktop/UNCC/Github/Fed-Learning/data\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb2ba65",
   "metadata": {},
   "source": [
    "<h2>Multi-layer Perceptron Model Architecture</h2>\n",
    "\n",
    "<t>*\"The initial experiment involves training an MLP with the MNIST dataset. This MLP comprises two\n",
    "hidden layers with 64 units each, utilizing the ReLU activation function\"*</t>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a326322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # MNIST images are 28x28\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)  # 10 classes for MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd4e94-9672-4540-99fa-b6362ed1fabe",
   "metadata": {},
   "source": [
    "<h2>CIFAR-10 CNN Model Architecture</h2>\n",
    "\n",
    "<t>*The second experiment focuses on training a Convolutional Neural Network CNN on the CIFAR-10 dataset. The CNN\n",
    "architecture encompasses two convolutional layers with max pooling, two fully connected layers, and a softmax output\n",
    "layer*</t>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42140649-bfe2-4b09-94b4-af2ed5f85f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(64*8*8, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae0be2-ae10-4ca1-bca7-15001291d51c",
   "metadata": {},
   "source": [
    "<h2>Federated Learning Algorithms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d5b39-4b0d-4dd1-b328-b6e3de8a6e11",
   "metadata": {},
   "source": [
    "<h3>Global Aggregator</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b6f9b57-59f8-4e51-b6f0-0764e8b14452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_aggregate(global_model, client_models):\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k] for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b49b5-990b-4555-8bb8-869eb940c037",
   "metadata": {},
   "source": [
    "<h3>Global Model Evaluation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab18ab62-95b1-4c67-8898-63c2d9eaf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(global_model, validation_loader):\n",
    "    global_model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = global_model(inputs)\n",
    "            loss += nn.CrossEntropyLoss()(output, labels).item()  # Using the criterion\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    loss /= len(validation_loader.dataset)\n",
    "    accuracy = correct / len(validation_loader.dataset)\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae079702",
   "metadata": {},
   "source": [
    "<h3>Client Update</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7c95129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_update(client, optimizer, training_loader, epochs):\n",
    "    client.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (inputs, labels) in enumerate(training_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = client(inputs)\n",
    "            loss = F.cross_entropy(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb069d-0da7-4b70-8677-2f91acec115a",
   "metadata": {},
   "source": [
    "<h2>Training with different schedulers</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0745d-63e2-4913-b616-09d8a32910df",
   "metadata": {},
   "source": [
    "<h3>Training using Random Scheduling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3a4fdfc-ded9-40db-b8be-57f8941cc696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNG_training(model_type, global_model, lr, total_clients, clients_per_round, total_rounds, local_epochs, training_loaders, validation_loader):\n",
    "    clients = [model_type().to(device) for _ in range(total_clients)]\n",
    "\n",
    "    for models in clients:\n",
    "        models.load_state_dict(global_model.state_dict())\n",
    "    \n",
    "    opt = [optim.SGD(models.parameters(), lr=lr) for models in clients]\n",
    "\n",
    "    average_losses, valid_losses, valid_accuracies = [], [], []\n",
    "\n",
    "    global_start_time = time.time()\n",
    "    for round in range(total_rounds):\n",
    "        start_time = time.time()\n",
    "        clients_idx = np.random.permutation(total_clients)[:clients_per_round]\n",
    "\n",
    "        client_losses = 0\n",
    "        selected_models = []\n",
    "        \n",
    "        for i in range(clients_per_round):\n",
    "            clients[clients_idx[i]].load_state_dict(global_model.state_dict())\n",
    "            client_losses += client_update(clients[clients_idx[i]], opt[clients_idx[i]], training_loaders[clients_idx[i]], local_epochs)\n",
    "            selected_models.append(clients[clients_idx[i]])\n",
    "        \n",
    "        global_aggregate(global_model, selected_models)\n",
    "    \n",
    "        avg_loss = client_losses / clients_per_round\n",
    "        valid_loss , valid_accuracy = model_evaluation(global_model, validation_loader)\n",
    "\n",
    "        average_losses.append(avg_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        round_time = end_time - start_time\n",
    "    \n",
    "        if (round % 10) == 0:\n",
    "            rounds_end_time = time.time()\n",
    "            rounds_time = rounds_end_time - global_start_time\n",
    "            print('Round {:3d}, Time (secs) {:.2f}: Average loss {:.4f}, Validation Loss {:.4f}, Validation Accuracy {:.4f}'.format(round + 1, rounds_time, avg_loss, valid_loss, valid_accuracy))\n",
    "    return average_losses, valid_losses, valid_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932137cf-fa6d-41fd-abd5-6d06817eebd5",
   "metadata": {},
   "source": [
    "<h3>Training using Age-based Scheduling</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d72cf797-2b05-414b-95a6-a8c289c3c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ABS_training(model_type, global_model, lr, total_clients, clients_per_round, total_rounds, local_epochs, training_loaders, validation_loader):\n",
    "    clients = [model_type().to(device) for _ in range(total_clients)]\n",
    "    \n",
    "    for models in clients:\n",
    "        models.load_state_dict(global_model.state_dict())\n",
    "    \n",
    "    opt = [optim.SGD(models.parameters(), lr=lr) for models in clients]\n",
    "    clients_age = np.zeros(total_clients)\n",
    "    \n",
    "    average_losses, valid_losses, valid_accuracies = [], [], []\n",
    "\n",
    "    global_start_time = time.time()\n",
    "    for round in range(total_rounds):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Age-based scheduling: select the clients with the highest age\n",
    "        old_clients_idx = np.argsort(clients_age)[-clients_per_round:]\n",
    "\n",
    "        clients_age += 1\n",
    "        clients_age[old_clients_idx] = 0  # Reset the age of the selected clients\n",
    "\n",
    "        client_losses = 0      \n",
    "        selected_models = []\n",
    "        \n",
    "        for i in range(clients_per_round):\n",
    "            clients[old_clients_idx[i]].load_state_dict(global_model.state_dict())\n",
    "            client_losses += client_update(clients[old_clients_idx[i]], opt[old_clients_idx[i]], training_loaders[old_clients_idx[i]], local_epochs)\n",
    "            selected_models.append(clients[old_clients_idx[i]])\n",
    "        \n",
    "\n",
    "        global_aggregate(global_model, selected_models)\n",
    "    \n",
    "        avg_loss = client_losses / clients_per_round\n",
    "        valid_loss , valid_accuracy = model_evaluation(global_model, validation_loader)\n",
    "\n",
    "        average_losses.append(avg_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        round_time = end_time - start_time\n",
    "    \n",
    "        if (round % 10) == 0:\n",
    "            rounds_end_time = time.time()\n",
    "            rounds_time = rounds_end_time - global_start_time\n",
    "            print('Round {:3d}, Time (secs) {:.2f}: Average loss {:.4f}, Validation Loss {:.4f}, Validation Accuracy {:.4f}'.format(round + 1, rounds_time, avg_loss, valid_loss, valid_accuracy))\n",
    "    return average_losses, valid_losses, valid_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b493a9ae",
   "metadata": {},
   "source": [
    "<h3>Training using Age of Update (AoU) OR Data Shapley value Scheduling</h3>\n",
    "\n",
    "<t>If a UE’s k AoU surpasses the threshold or its Data Shapley value exceeds the Shapley value of the current highest value in the list, or both conditions are met,\n",
    "the UE k is positioned at the beginning of the list; otherwise, it is placed at the end</t>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7eb41348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_map(client_models, training_loaders):\n",
    "    client_map = {}\n",
    "    for idx, client_model in enumerate(client_models):\n",
    "        client_id = f\"client_{idx + 1}\"\n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=lr)\n",
    "        client_map[client_id] = {\n",
    "            'model': client_model,\n",
    "            'optimizer': optimizer,\n",
    "            'training_loader': training_loaders[idx],\n",
    "            'accuracies': [],\n",
    "            'losses': [],\n",
    "            'shapley_value': random.random(),\n",
    "            'age': 0\n",
    "        }\n",
    "    return client_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd955f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_performance(client_map, selected_clients, shapley_threshold):\n",
    "    for client_id in client_map.keys():\n",
    "        if client_id in selected_clients:\n",
    "            client_accuracies = client_map[client_id][\"accuracies\"]\n",
    "            mean_acc = sum(client_accuracies) / len(client_accuracies)\n",
    "            variance = sum(((x - mean_acc) ** 2) for x in client_accuracies) / len(client_accuracies)\n",
    "            if variance > shapley_threshold:\n",
    "                updated_value = client_map[client_id][\"shapley_value\"] + 1.0    \n",
    "            else:\n",
    "                updated_value = client_map[client_id][\"shapley_value\"]\n",
    "        else:\n",
    "            updated_value = client_map[client_id][\"shapley_value\"] \n",
    "\n",
    "        mean_performance_score = (sum(client_map[client_id][\"losses\"]) + updated_value) / (len(client_map[client_id][\"losses\"]) + 1)\n",
    "        client_map[client_id][\"shapley_value\"] = mean_performance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9fa9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scheduling_Policy(client_map, AoU_threshold, clients_per_round):\n",
    "    selected_clients = []\n",
    "    client_position = []\n",
    "    highest_score = max(client_map.values(), key=lambda x: x['shapley_value'])['shapley_value']\n",
    "    \n",
    "    for client_id, client_info in client_map.items():\n",
    "        client_score = client_info['shapley_value']\n",
    "        client_age = client_info['age']\n",
    "        \n",
    "        if client_score >= highest_score or client_age > AoU_threshold:\n",
    "            client_position.insert(0, client_id)  # Prepend the client ID\n",
    "        else:\n",
    "            client_position.append(client_id)\n",
    "\n",
    "    for i in range(clients_per_round):\n",
    "        selected_clients.append(client_position[i])\n",
    "\n",
    "    return selected_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1610f452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_client(client_map, selected_clients, local_epochs, validation_loader, global_model, performance_threshold):\n",
    "    for client_id in selected_clients:\n",
    "        client_map[client_id]['model'].load_state_dict(global_model.state_dict())\n",
    "        model = client_map[client_id]['model']\n",
    "        model.train()\n",
    "\n",
    "        optimizer = client_map[client_id]['optimizer']\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(local_epochs):\n",
    "            for inputs, labels in client_map[client_id]['training_loader']:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accuracy = correct / (len(validation_loader.dataset))\n",
    "\n",
    "        client_map[client_id]['accuracies'].append(accuracy)\n",
    "        client_map[client_id]['losses'].append(loss.item())\n",
    "    \n",
    "    update_performance(client_map, selected_clients, performance_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b862cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AoU_OR_DataShapley_training(model_type, global_model, total_clients, clients_per_round, total_rounds, local_epochs, training_loaders, validation_loader, age_threshold, shapley_threshold):\n",
    "    client_models = [model_type().to(device) for _ in range(total_clients)]\n",
    "    for models in client_models:\n",
    "        models.load_state_dict(global_model.state_dict())\n",
    "\n",
    "    client_map = create_client_map(client_models, training_loaders)\n",
    "\n",
    "    average_losses, valid_losses, valid_accuracies = [], [], []\n",
    "\n",
    "    global_start_time = time.time()\n",
    "    for round in range(total_rounds):\n",
    "        start_time = time.time()\n",
    "\n",
    "        selected_clients = Scheduling_Policy(client_map, age_threshold, clients_per_round)\n",
    "\n",
    "        for client_id in client_map:\n",
    "            client_map[client_id]['age'] = client_map[client_id]['age'] ** 2 + 1\n",
    "\n",
    "        # Reset the age of selected clients to 0\n",
    "        for client_id in selected_clients:\n",
    "            client_map[client_id]['age'] = 0\n",
    "        \n",
    "        train_and_test_client(client_map, selected_clients, local_epochs, validation_loader, global_model, shapley_threshold)        \n",
    "        update_performance(client_map, selected_clients, shapley_threshold)\n",
    "        global_aggregate(global_model, [client_map[client_id]['model'] for client_id in selected_clients])\n",
    "\n",
    "        client_losses = sum(client_map[client_id]['losses'][-1] for client_id in selected_clients)\n",
    "    \n",
    "        avg_loss = client_losses / len(selected_clients)\n",
    "        valid_loss , valid_accuracy = model_evaluation(global_model, validation_loader)\n",
    "\n",
    "        average_losses.append(avg_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        round_time = end_time - start_time\n",
    "    \n",
    "        if (round % 10) == 0:\n",
    "            rounds_end_time = time.time()\n",
    "            rounds_time = rounds_end_time - global_start_time\n",
    "            print('Round {:3d}, Time (secs) {:.2f}: Average loss {:.4f}, Validation Loss {:.4f}, Validation Accuracy {:.4f}'.format(round + 1, rounds_time, avg_loss, valid_loss, valid_accuracy))\n",
    "\n",
    "    return average_losses, valid_losses, valid_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba53e445",
   "metadata": {},
   "source": [
    "<h2>Hyperparameters for Training Experience</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4871860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration: use CUDA if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Learning configuration\n",
    "lr = 0.015\n",
    "total_rounds = 25  # Total number of training rounds\n",
    "\n",
    "# Client configuration\n",
    "total_clients = 100  # Total number of clients\n",
    "clients_per_round = 10  # Number of clients selected per round\n",
    "\n",
    "# Local training configuration\n",
    "local_batchsize = 50  # Batch size for local training\n",
    "local_epochs = 5  # Number of epochs for local training\n",
    "\n",
    "shapley_threshold = 0.8\n",
    "age_threshold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a05ed",
   "metadata": {},
   "source": [
    "<h2>IID Data Preparation for MNIST and CIFAR-10 Dataset</h2>\n",
    "<t>*The IID data is shuffled and then divided up across 100 clients each receiving 600 examples.*  \n",
    "\n",
    "*Exclusively use independent and identically distributed i.i.d. distributions for CIFAR-10 due to the absence of a natural\n",
    "data user partition*</t>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6fd5e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "MNISTtransform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# MNIST IID Dataset\n",
    "MNIST_training_dataset = datasets.MNIST(filepath, train=True, download=True, transform=MNISTtransform)\n",
    "MNIST_training_datasplit = torch.utils.data.random_split(MNIST_training_dataset, [int(MNIST_training_dataset.data.shape[0] / total_clients) for _ in range(total_clients)])\n",
    "MNIST_iid_training = [torch.utils.data.DataLoader(x, batch_size=local_batchsize, shuffle=True) for x in MNIST_training_datasplit]\n",
    "\n",
    "MNIST_validation_dataset = datasets.MNIST(filepath, train=False, download = True, transform=MNISTtransform)\n",
    "MNIST_iid_validation = torch.utils.data.DataLoader(MNIST_validation_dataset, batch_size=local_batchsize, shuffle=True)\n",
    "\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "CIFARtransform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(filepath, train=True, download=True, transform=CIFARtransform)\n",
    "\n",
    "CIFAR10_dataset = torch.utils.data.random_split(dataset, [len(dataset) // total_clients for _ in range(total_clients)])\n",
    "CIFAR10_training = [torch.utils.data.DataLoader(x, batch_size=local_batchsize, shuffle=True) for x in CIFAR10_dataset]\n",
    "\n",
    "CIFAR10_validation = torch.utils.data.DataLoader(datasets.CIFAR10(filepath, train=False, transform=CIFARtransform), batch_size=local_batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950a6f7-30e7-48a1-98ac-355225b54c3d",
   "metadata": {},
   "source": [
    "<h3>MLP Model Training with MNIST IID</h3>\n",
    "\n",
    "Training is done using *'Random'* Scheduling, *'Age-based'* Scheduling, and *'Age of Update OR Data Shapley'* Scheduling (See RNG_training, ABS_training, AoU_OR_DataShapley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c46bef3-dd48-451f-8877-c5d44cd4b540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training: Model - MLP, Schedule - Random, Data Distribution - MNIST IID  ===\n",
      "Round   1, Time (secs) 7.30: Average loss 1.9741, Validation Loss 0.0400, Validation Accuracy 0.4812\n",
      "Round  11, Time (secs) 79.48: Average loss 0.3076, Validation Loss 0.0066, Validation Accuracy 0.9054\n",
      "Round  21, Time (secs) 151.17: Average loss 0.2057, Validation Loss 0.0053, Validation Accuracy 0.9241\n",
      "Round  31, Time (secs) 223.09: Average loss 0.1591, Validation Loss 0.0045, Validation Accuracy 0.9338\n",
      "Round  41, Time (secs) 296.56: Average loss 0.1061, Validation Loss 0.0040, Validation Accuracy 0.9414\n",
      "\n",
      "=== Training: Model - MLP, Schedule - Age-Based, Data Distribution - MNIST IID ===\n",
      "Round   1, Time (secs) 7.35: Average loss 1.9840, Validation Loss 0.0395, Validation Accuracy 0.6355\n",
      "Round  11, Time (secs) 82.38: Average loss 0.2916, Validation Loss 0.0064, Validation Accuracy 0.9081\n",
      "Round  21, Time (secs) 157.46: Average loss 0.2263, Validation Loss 0.0051, Validation Accuracy 0.9251\n",
      "Round  31, Time (secs) 232.13: Average loss 0.1582, Validation Loss 0.0044, Validation Accuracy 0.9350\n",
      "Round  41, Time (secs) 305.98: Average loss 0.0987, Validation Loss 0.0038, Validation Accuracy 0.9427\n",
      "\n",
      "=== Training: Model - MLP, Schedule - Age of Update OR Data Shapley, Data Distribution - MNIST IID ===\n",
      "Round   1, Time (secs) 24.41: Average loss 1.9455, Validation Loss 0.0396, Validation Accuracy 0.5058\n",
      "Round  11, Time (secs) 263.61: Average loss 0.2908, Validation Loss 0.0067, Validation Accuracy 0.9025\n",
      "Round  21, Time (secs) 503.63: Average loss 0.2078, Validation Loss 0.0054, Validation Accuracy 0.9195\n"
     ]
    }
   ],
   "source": [
    "MNIST_iid_RNG = MLP().to(device)\n",
    "MNIST_iid_ABS = MLP().to(device)\n",
    "MNIST_iid_AoU_OR_DataShapley = MLP().to(device)\n",
    "\n",
    "print(\"=== Training: Model - MLP, Schedule - Random, Data Distribution - MNIST IID  ===\")\n",
    "iid_MNIST_RNG_avg_losses, iid_MNIST_RNG_eval_losses, iid_MNIST_RNG_accuracies = RNG_training(MLP, MNIST_iid_RNG, lr, total_clients, clients_per_round, total_rounds, local_epochs, MNIST_iid_training, MNIST_iid_validation)\n",
    "\n",
    "print(\"\\n=== Training: Model - MLP, Schedule - Age-Based, Data Distribution - MNIST IID ===\")\n",
    "iid_MNIST_ABS_avg_losses, iid_MNIST_ABS_eval_losses, iid_MNIST_ABS_accuracies = ABS_training(MLP, MNIST_iid_ABS, lr, total_clients, clients_per_round, total_rounds, local_epochs, MNIST_iid_training, MNIST_iid_validation)\n",
    "\n",
    "print(\"\\n=== Training: Model - MLP, Schedule - Age of Update OR Data Shapley, Data Distribution - MNIST IID ===\")\n",
    "iid_MNIST_AoU_OR_DataShapley_avg_losses, iid_MNIST_AoU_OR_DataShapley_eval_losses, iid_MNIST_AoU_OR_DataShapley_accuracies = AoU_OR_DataShapley_training(MLP, MNIST_iid_AoU_OR_DataShapley, total_clients, clients_per_round, total_rounds, local_epochs, MNIST_iid_training, MNIST_iid_validation, age_threshold, shapley_threshold)\n",
    "\n",
    "# Save Final Models\n",
    "torch.save(MNIST_iid_RNG.state_dict(), '.\\\\Models\\\\MNIST_iid_RNG.pth')\n",
    "torch.save(MNIST_iid_ABS.state_dict(), '.\\\\Models\\\\MNIST_iid_ABS.pth')\n",
    "torch.save(MNIST_iid_AoU_OR_DataShapley.state_dict(), '.\\\\Models\\\\MNIST_iid_AoU_OR_DataShapley.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df303c0",
   "metadata": {},
   "source": [
    "<h4>MLP Model Training/Inferencing Experience Comparison for MNIST IID</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9392157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'=================================== Final MLP Model Accuracies per Schedule ====================================')\n",
    "print(f'Random Scheduled MNIST IID Model Accuracy: {iid_MNIST_RNG_accuracies[-1]},\\nAge-based Scheduled MNIST IID  Model Accuracy: {iid_MNIST_ABS_accuracies[-1]},\\nAoU OR DataShapley Scheduled MNIST IID Model Accuracy: {iid_MNIST_AoU_OR_DataShapley_accuracies[-1]}')\n",
    "print(f'================================================================================================================')\n",
    "L\n",
    "epochs_range = range(1, total_rounds + 1)\n",
    "\n",
    "# Plot Global Training Loss\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, iid_MNIST_RNG_eval_losses, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.plot(epochs_range, iid_MNIST_ABS_eval_losses, color='blue', linestyle=\"dotted\", label=\"Age-based Schedule\")\n",
    "plt.plot(epochs_range, iid_MNIST_AoU_OR_DataShapley_eval_losses, color='green', linestyle=\"solid\", label=\"AoU OR DataShapley Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.legend(loc='upper right')  \n",
    "plt.title('MLP MNIST IID Loss Curve')\n",
    "\n",
    "# Plot Global Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, iid_MNIST_RNG_accuracies, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.plot(epochs_range, iid_MNIST_ABS_accuracies, color='blue', linestyle=\"dotted\", label=\"Age-based Schedule\")\n",
    "plt.plot(epochs_range, iid_MNIST_AoU_OR_DataShapley_accuracies, color='green', linestyle=\"solid\", label=\"AoU OR DataShapley Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.legend(loc='lower right') \n",
    "plt.title('MLP MNIST IID Accuracy Curve')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('.\\\\Plots\\\\mnist_iid_results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebeb150",
   "metadata": {},
   "source": [
    "<h3>CNN Model Training with CIFAR-10 IID</h3>\n",
    "\n",
    "Training is done using *'Random'* Scheduling, *'Age-based'* Scheduling, and *'Age of Update OR Data Shapley'* Scheduling (See RNG_training, ABS_training, AoU_OR_DataShapley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695659a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR10_iid_RNG = CNN().to(device)\n",
    "CIFAR10_iid_ABS = CNN().to(device)\n",
    "CIFAR10_iid_AoU_OR_DataShapley = CNN().to(device)\n",
    "\n",
    "print(\"=== Training: Model - CNN, Schedule - Random, Data Distribution - IID CIFAR-10 ===\")\n",
    "iid_CIFAR10_RNG_avg_losses, iid_CIFAR10_RNG_eval_losses, iid_CIFAR10_RNG_accuracies = RNG_training(CNN, CIFAR10_iid_RNG, lr, total_clients, clients_per_round, total_rounds, local_epochs, CIFAR10_training, CIFAR10_validation)\n",
    "\n",
    "print(\"\\n=== Training: Model - CNN, Schedule - Age-Based, Data Distribution - IID CIFAR-10 ===\")\n",
    "iid_CIFAR10_ABS_avg_losses, iid_CIFAR10_ABS_eval_losses, iid_CIFAR10_ABS_accuracies = ABS_training(CNN, CIFAR10_iid_ABS, lr, total_clients, clients_per_round, total_rounds, local_epochs, CIFAR10_training, CIFAR10_validation)\n",
    "\n",
    "print(\"\\n=== Training: Model - CNN, Schedule - Age of Update OR Data Shapley, Data Distribution - IID CIFAR-10 ===\")\n",
    "iid_CIFAR10_AoU_OR_DataShapley_avg_losses, iid_CIFAR10_AoU_OR_DataShapley_eval_losses, iid_CIFAR10_AoU_OR_DataShapley_accuracies = AoU_OR_DataShapley_training(CNN, CIFAR10_iid_AoU_OR_DataShapley, lr, total_clients, clients_per_round, total_rounds, local_epochs, CIFAR10_training, CIFAR10_validation, age_threshold, shapley_threshold)\n",
    "\n",
    "# Save Final Models\n",
    "torch.save(CIFAR10_iid_RNG.state_dict(), '.\\\\Models\\\\CIFAR10_iid_RNG.pth')\n",
    "torch.save(CIFAR10_iid_ABS.state_dict(), '.\\\\Models\\\\CIFAR10_iid_ABS.pth')\n",
    "torch.save(CIFAR10_iid_AoU_OR_DataShapley.state_dict(), '.\\\\Models\\\\CIFAR10_iid_AoU_OR_DataShapley.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbe39c",
   "metadata": {},
   "source": [
    "<h4>CNN Model Training/Inferencing Experience Comparison for CIFAR-10 IID</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff00339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'=================================== Final CNN Model Accuracies per Schedule ====================================')\n",
    "print(f'Random Scheduled CIFAR-10 IID Model Accuracy: {iid_CIFAR10_RNG_accuracies[-1]},\\nAge-based Scheduled CIFAR-10 IID  Model Accuracy: {iid_CIFAR10_ABS_accuracies[-1]},\\nAoU OR DataShapley Scheduled CIFAR-10 IID Model Accuracy: {iid_CIFAR10_AoU_OR_DataShapley_accuracies[-1]}')\n",
    "print(f'================================================================================================================')\n",
    "\n",
    "epochs_range = range(1, total_rounds + 1)\n",
    "\n",
    "# Plot Global Training Loss\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, iid_CIFAR10_RNG_eval_losses, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.plot(epochs_range, iid_CIFAR10_ABS_eval_losses, color='blue', linestyle=\"dotted\", label=\"Age-based Schedule\")\n",
    "plt.plot(epochs_range, iid_CIFAR10_AoU_OR_DataShapley_eval_losses, color='green', linestyle=\"solid\", label=\"AoU OR DataShapley Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.legend(loc='upper right')  \n",
    "plt.title('CNN CIFAR-10 IID Loss Curve')\n",
    "\n",
    "# Plot Global Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, iid_CIFAR10_RNG_accuracies, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.plot(epochs_range, iid_CIFAR10_ABS_accuracies, color='blue', linestyle=\"dotted\", label=\"Age-based Schedule\")\n",
    "plt.plot(epochs_range, iid_CIFAR10_AoU_OR_DataShapley_accuracies, color='green', linestyle=\"solid\", label=\"AoU OR DataShapley Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.legend(loc='lower right') \n",
    "plt.title('CNN CIFAR-10 IID Accuracy Curve')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('.\\\\Plots\\\\cifar10_iid_results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abe98ad",
   "metadata": {},
   "source": [
    "<h2>Non-IID Data Preparation for MNIST Dataset</h2>\n",
    "\n",
    "<t>*The Non-IID data is sorted by digit label, divided up into 200 'shards' of 300 examples, and then each client receieves 2 'shards'*</t>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e5d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Non-IID Dataset\n",
    "training_labels = torch.stack([MNIST_training_dataset.targets == i for i in range(10)])\n",
    "training_labels_split = []\n",
    "\n",
    "for i in range(5):\n",
    "    training_labels_split += torch.split(torch.where(training_labels[(2 * i):(2 * (i + 1))].sum(0))[0], int(len(MNIST_training_dataset.data) / total_clients))\n",
    "training_dataset_split = [torch.utils.data.Subset(MNIST_training_dataset, labels) for labels in training_labels_split]\n",
    "MNIST_noniid_training = [torch.utils.data.DataLoader(x, batch_size=local_batchsize, shuffle=True) for x in training_dataset_split]\n",
    "\n",
    "MNIST_noniid_validation = torch.utils.data.DataLoader(MNIST_validation_dataset, batch_size=local_batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ae80f-38f6-483c-a801-e96c63f24e1c",
   "metadata": {},
   "source": [
    "<h3>MLP Model Training with MNIST Non-IID</h3>\n",
    "\n",
    "Training is done using *'Random'* Scheduling, *'Age-based'* Scheduling, and *'Age of Update OR Data Shapley'* Scheduling (See RNG_training, ABS_training, AoU_OR_DataShapley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f6dfe-7a37-474a-bf51-3f45ffd92be6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MNIST_noniid_RNG = MLP().to(device)\n",
    "MNIST_noniid_ABS = MLP().to(device)\n",
    "MNIST_noniid_AoU_OR_DataShapley = MLP().to(device)\n",
    "\n",
    "print(\"=== Training: Model - MLP, Schedule - Random, Data Distribution - MNIST Non-IID  ===\")\n",
    "noniid_MNIST_RNG_avg_losses, noniid_MNIST_RNG_eval_losses, noniid_MNIST_RNG_accuracies = RNG_training(MLP, MNIST_noniid_RNG, lr, total_clients, clients_per_round, total_rounds, local_epochs, MNIST_noniid_training, MNIST_noniid_validation)\n",
    "\n",
    "print(\"\\n=== Training: Model - MLP, Schedule - Age-Based, Data Distribution - MNIST Non-IID  ===\")\n",
    "noniid_MNIST_ABS_avg_losses, noniid_MNIST_ABS_eval_losses, noniid_MNIST_ABS_accuracies = ABS_training(MLP, MNIST_noniid_ABS, lr, total_clients, clients_per_round, total_rounds, local_epochs, MNIST_noniid_training, MNIST_noniid_validation)\n",
    "\n",
    "print(\"\\n=== Training: Model - MLP, Schedule - Age of Update OR Data Shapley, Data Distribution - MNIST Non-IID  ===\")\n",
    "noniid_MNIST_AoU_OR_DataShapley_avg_losses, noniid_MNIST_AoU_OR_DataShapley_eval_losses, noniid_MNIST_AoU_OR_DataShapley_accuracies = AoU_OR_DataShapley_training(MLP, MNIST_noniid_AoU_OR_DataShapley, lr, total_clients, clients_per_round, total_rounds, local_epochs, MNIST_noniid_training, MNIST_noniid_validation, age_threshold, shapley_threshold)\n",
    "\n",
    "torch.save(MNIST_noniid_RNG.state_dict(), '.\\\\Models\\\\MNIST_noniid_RNG.pth')\n",
    "torch.save(MNIST_noniid_ABS.state_dict(), '.\\\\Models\\\\MNIST_noniid_ABS.pth')\n",
    "torch.save(MNIST_noniid_AoU_OR_DataShapley.state_dict(), '.\\\\Models\\\\MNIST_noniid_AoU_OR_DataShapley.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a174e20d",
   "metadata": {},
   "source": [
    "<h4>MLP Model Training/Inferencing Experience Comparison for MNIST Non-IID</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54d30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'=================================== Final MLP Model Accuracies per Schedule ====================================')\n",
    "print(f'Random Scheduled MNIST Non-IID Model Accuracy: {noniid_MNIST_RNG_accuracies[-1]},\\nAge-based Scheduled MNIST Non-IID  Model Accuracy: {noniid_MNIST_ABS_accuracies[-1]},\\nAoU OR DataShapley Scheduled MNIST Non-IID Model Accuracy: {noniid_MNIST_AoU_OR_DataShapley_accuracies[-1]}')\n",
    "print(f'================================================================================================================')\n",
    "\n",
    "epochs_range = range(1, total_rounds + 1)\n",
    "\n",
    "# Plot Global Training Loss\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, noniid_MNIST_RNG_eval_losses, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.plot(epochs_range, noniid_MNIST_ABS_eval_losses, color='blue', linestyle=\"dotted\", label=\"Age-based Schedule\")\n",
    "plt.plot(epochs_range, noniid_MNIST_AoU_OR_DataShapley_eval_losses, color='green', linestyle=\"solid\", label=\"AoU OR DataShapley Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.legend(loc='upper right')  \n",
    "plt.title('MLP MNIST Non-IID Loss Curve')\n",
    "\n",
    "# Plot Global Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, noniid_MNIST_RNG_accuracies, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.plot(epochs_range, noniid_MNIST_ABS_accuracies, color='blue', linestyle=\"dotted\", label=\"Age-based Schedule\")\n",
    "plt.plot(epochs_range, noniid_MNIST_AoU_OR_DataShapley_accuracies, color='green', linestyle=\"solid\", label=\"AoU OR DataShapley Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.legend(loc='lower right') \n",
    "plt.title('MLP MNIST Non-IID Accuracy Curve')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('.\\\\Plots\\\\mnist_noniid_results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a5be7-0d5f-4a5f-bb66-3f6d90f0f40f",
   "metadata": {},
   "source": [
    "<h2>Global Model Complexity Comparisons</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c8424-d84b-46d3-9113-df79df2d5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_summary(model, model_name, dataset_name):\n",
    "    if dataset_name == \"MNIST\":\n",
    "        input_size = (1, 28, 28)\n",
    "    elif dataset_name == \"CIFAR-10\":\n",
    "        input_size = (3, 32, 32)\n",
    "\n",
    "    model_stats = summary(model, input_size=input_size, col_width=16, col_names=[\"kernel_size\", \"output_size\", \"num_params\", \"mult_adds\"], row_settings=[\"var_names\"])\n",
    "    print(f\"\\n{'='*30} {model_name} {'='*30}\")\n",
    "    print(model_stats)\n",
    "    print('='*80)\n",
    "\n",
    "print(\"\\t\\t\\t\\tMLP Model Comparisons using MNIST IID\\n\")\n",
    "print_model_summary(MNIST_iid_RNG, \"Random IID Model\", \"MNIST\")\n",
    "print_model_summary(MNIST_iid_ABS, \"Age-Based IID Model\", \"MNIST\")\n",
    "print_model_summary(MNIST_iid_AoU_OR_DataShapley, \"AoU OR DataShapley IID Model\", \"MNIST\")\n",
    "print()\n",
    "\n",
    "print(\"\\t\\t\\t\\tMLP Model Comparisons using MNIST Non-IID\\n\")\n",
    "print_model_summary(MNIST_noniid_RNG, \"Random Non-IID Model\", \"MNIST\")\n",
    "print_model_summary(MNIST_noniid_ABS, \"Age-Based Non-IID Model\", \"MNIST\")\n",
    "print_model_summary(MNIST_noniid_AoU_OR_DataShapley, \"AoU OR DataShapley Non-IID Model\", \"MNIST\")\n",
    "print()\n",
    "\n",
    "print(\"\\t\\t\\t\\tCNN Model Comparisons using CIFAR10 IID\\n\")\n",
    "print_model_summary(CIFAR10_iid_RNG, \"Random IID Model\", \"CIFAR-10\")\n",
    "print_model_summary(CIFAR10_iid_ABS, \"Age-Based IID Model\", \"CIFAR-10\")\n",
    "print_model_summary(CIFAR10_iid_AoU_OR_DataShapley, \"AoU OR DataShapley IID Model\", \"CIFAR-10\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
