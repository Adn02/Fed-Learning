{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Global Dependencies\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import Helper Libaries\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "filepath = \"C:/Users/aidan_000/Desktop/UNCC/Github/Fed-Learning/data\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CIFAR-10 CNN Model Architecture</h2>\n",
    "\n",
    "<t>*The second experiment focuses on training a Convolutional Neural Network CNN on the CIFAR-10 dataset. The CNN\n",
    "architecture encompasses two convolutional layers with max pooling, two fully connected layers, and a softmax output\n",
    "layer*</t>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
    "        self.fc1 = nn.Linear(64*8*8, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Federated Learning Algorithms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Global Aggregator with Selected Clients' Quantized Vectors</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_aggregate(global_model, client_models):\n",
    "    global_dict = global_model.state_dict()\n",
    "    quantized_updates = []\n",
    "    for i, client_model in enumerate(client_models):\n",
    "        # Quantize the difference between the client's final local model and the global model\n",
    "        quantized_update = Q(client_model.state_dict() - global_dict)\n",
    "        quantized_updates.append(quantized_update)\n",
    "    \n",
    "    # Aggregate the quantized updates and update the global model\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = global_dict[k] + (1 / len(client_models)) * torch.stack(\n",
    "            [update[k] for update in quantized_updates], 0\n",
    "        ).mean(0)\n",
    "    \n",
    "    global_model.load_state_dict(global_dict)\n",
    "    \n",
    "    # Update the client models with the new global model\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Global Model Evaluation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(global_model, validation_loader):\n",
    "    global_model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = global_model(inputs)\n",
    "            loss += nn.CrossEntropyLoss()(output, labels).item()  # Using the criterion\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    loss /= len(validation_loader.dataset)\n",
    "    accuracy = correct / len(validation_loader.dataset)\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Client Update</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_update(client, optimizer, training_loader, epochs):\n",
    "    client.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (inputs, labels) in enumerate(training_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = client(inputs)\n",
    "            loss = F.cross_entropy(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training using Random Scheduling</h3>\n",
    "\n",
    "1. Periodic averaging: Let the participating nodes conduct a number of local updates and synchronize through the parameter server periodically. To be more specific, once nodes pull an updated model from the server, they update the model locally by running iterations of the SGD method and then send proper information to the server for updating the aggregate model.\n",
    "\n",
    "2. Partial node participation: Each round of the training algorithm the parameter server sends its current model X<sub>k</sub> to all the _r_ nodes in subset _S<sub>k</sub>_, which are distributed uniformly at random among the total _n_ nodes\n",
    "\n",
    "3. Quantized message-passing: each node _i_ ∈ _S<sub>k</sub>_ obtains the model **x**<sup>(_i_)</sup><sub>_k,τ_</sub> after running τ local iterations of an optimization method (SGD) on the most recent model **x**<sub>_k_</sub> that it has receieved from the server. Then each node _i_ applies a quantizer operator _Q(·)_ on the difference between the recieved model and its updated model, i.e., **x**<sup>(_i_)</sup><sub>_k,τ_</sub>  -  **x**<sub>_k_</sub> and then uploads the quantized vector _Q(**x**<sup>(i)</sup><sub>k,τ</sub>  -  **x**<sub>k</sub>)_ to the parameter server. Once these quantized vectors are sent to the server, it decodes the quantized signals and combines them to come up with a new model **x**<sub>_k_+1</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QLP_i(x, s):\n",
    "    \"\"\"Low-precision quantizer for the i-th element of vector x\"\"\"\n",
    "    norm_x = torch.norm(x)\n",
    "    sign_x_i = torch.sign(x)\n",
    "    l = random.randint(0, s)\n",
    "    \n",
    "    # Generate the random variable ξ_i(x, s)\n",
    "    prob = abs(x) / (norm_x * s) - l\n",
    "    xi = (l+1)/s if random.random() < prob else l/s\n",
    "    \n",
    "    return norm_x * sign_x_i * xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_aggregate(global_model, client_models, quantization_level):\n",
    "    global_dict = global_model.state_dict()\n",
    "    quantized_updates = []\n",
    "    for i, client_model in enumerate(client_models):\n",
    "        # Compute the difference between the client's final local model and the global model\n",
    "        model_diff = {k: client_model.state_dict()[k] - global_dict[k] for k in global_dict.keys()}\n",
    "        \n",
    "        # Quantize the difference using the low-precision quantizer\n",
    "        quantized_update = {k: QLP_i(model_diff[k], quantization_level) for k in model_diff.keys()}\n",
    "        quantized_updates.append(quantized_update)\n",
    "    \n",
    "    # Aggregate the quantized updates and update the global model\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = global_dict[k] + (1 / len(client_models)) * torch.stack(\n",
    "            [update[k] for update in quantized_updates], 0\n",
    "        ).mean(0)\n",
    "    \n",
    "    global_model.load_state_dict(global_dict)\n",
    "    \n",
    "    # Update the client models with the new global model\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNG_training(model_type, global_model, lr, total_clients, clients_per_round, total_rounds, local_epochs, training_loaders, validation_loader, quantization_level):\n",
    "    clients = [model_type().to(device) for _ in range(total_clients)]\n",
    "\n",
    "    for models in clients:\n",
    "        models.load_state_dict(global_model.state_dict())\n",
    "    \n",
    "    opt = [optim.SGD(models.parameters(), lr=lr) for models in clients]\n",
    "\n",
    "    average_losses, valid_losses, valid_accuracies = [], [], []\n",
    "\n",
    "    global_start_time = time.time()\n",
    "    for round in range(total_rounds):\n",
    "        start_time = time.time()\n",
    "        clients_idx = np.random.permutation(total_clients)[:clients_per_round]\n",
    "\n",
    "        client_losses = 0\n",
    "        selected_models = []\n",
    "        \n",
    "        for i in range(clients_per_round):\n",
    "            clients[clients_idx[i]].load_state_dict(global_model.state_dict())\n",
    "            client_losses += client_update(clients[clients_idx[i]], opt[clients_idx[i]], training_loaders[clients_idx[i]], local_epochs)\n",
    "            selected_models.append(clients[clients_idx[i]])\n",
    "        \n",
    "        global_aggregate(global_model, selected_models, quantization_level)\n",
    "    \n",
    "        avg_loss = client_losses / clients_per_round\n",
    "        valid_loss , valid_accuracy = model_evaluation(global_model, validation_loader)\n",
    "\n",
    "        average_losses.append(avg_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        round_time = end_time - start_time\n",
    "    \n",
    "        if (round % 10) == 0:\n",
    "            rounds_end_time = time.time()\n",
    "            rounds_time = rounds_end_time - global_start_time\n",
    "            print('Round {:3d}, Time (secs) {:.2f}: Average loss {:.4f}, Validation Loss {:.4f}, Validation Accuracy {:.4f}'.format(round + 1, rounds_time, avg_loss, valid_loss, valid_accuracy))\n",
    "    return average_losses, valid_losses, valid_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training using Age-based (AoU)</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ABS_training(model_type, global_model, lr, total_clients, clients_per_round, total_rounds, local_epochs, training_loaders, validation_loader,):\n",
    "    clients = [model_type().to(device) for _ in range(total_clients)]\n",
    "    \n",
    "    for models in clients:\n",
    "        models.load_state_dict(global_model.state_dict())\n",
    "    \n",
    "    opt = [optim.SGD(models.parameters(), lr=lr) for models in clients]\n",
    "    clients_age = np.zeros(total_clients)\n",
    "    \n",
    "    average_losses, valid_losses, valid_accuracies = [], [], []\n",
    "\n",
    "    global_start_time = time.time()\n",
    "    for round in range(total_rounds):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Age-based scheduling: select the clients with the highest age\n",
    "        old_clients_idx = np.argsort(clients_age)[-clients_per_round:]\n",
    "\n",
    "        clients_age += 1\n",
    "        clients_age[old_clients_idx] = 0  # Reset the age of the selected clients\n",
    "\n",
    "        client_losses = 0      \n",
    "        selected_models = []\n",
    "        \n",
    "        for i in range(clients_per_round):\n",
    "            clients[old_clients_idx[i]].load_state_dict(global_model.state_dict())\n",
    "            client_losses += client_update(clients[old_clients_idx[i]], opt[old_clients_idx[i]], training_loaders[old_clients_idx[i]], local_epochs)\n",
    "            selected_models.append(clients[old_clients_idx[i]])\n",
    "        \n",
    "\n",
    "        global_aggregate(global_model, selected_models)\n",
    "    \n",
    "        avg_loss = client_losses / clients_per_round\n",
    "        valid_loss , valid_accuracy = model_evaluation(global_model, validation_loader)\n",
    "\n",
    "        average_losses.append(avg_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append(valid_accuracy)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        round_time = end_time - start_time\n",
    "    \n",
    "        if (round % 10) == 0:\n",
    "            rounds_end_time = time.time()\n",
    "            rounds_time = rounds_end_time - global_start_time\n",
    "            print('Round {:3d}, Time (secs) {:.2f}: Average loss {:.4f}, Validation Loss {:.4f}, Validation Accuracy {:.4f}'.format(round + 1, rounds_time, avg_loss, valid_loss, valid_accuracy))\n",
    "    return average_losses, valid_losses, valid_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hyperparameters for Training Experience</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration: use CUDA if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Learning configuration\n",
    "lr = 0.15\n",
    "total_rounds = 100  # Total number of training rounds, Denoted as T\n",
    "\n",
    "# Client configuration\n",
    "total_clients = 100  # Total number of clients\n",
    "clients_per_round = int(0.2*total_clients)  # Number of clients selected per round, Denoted as r\n",
    "\n",
    "# Local training configuration\n",
    "local_batchsize = 10  # Batch size for local training\n",
    "local_epochs = 10  # Denoted as tau (little T)\n",
    "\n",
    "quantization_level = 1 # Denoted as s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>IID Data Preparation for the CIFAR-10 Dataset</h2>\n",
    "<t>*The IID data is shuffled and then divided up across 100 clients each receiving 600 examples.*  \n",
    "\n",
    "*Exclusively use independent and identically distributed i.i.d. distributions for CIFAR-10 due to the absence of a natural\n",
    "data user partition*</t>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "CIFARtransform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to tensor\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) \n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(filepath, train=True, download=True, transform=CIFARtransform)\n",
    "\n",
    "CIFAR10_dataset = torch.utils.data.random_split(dataset, [len(dataset) // total_clients for _ in range(total_clients)])\n",
    "CIFAR10_training = [torch.utils.data.DataLoader(x, batch_size=local_batchsize, shuffle=True) for x in CIFAR10_dataset]\n",
    "\n",
    "CIFAR10_validation = torch.utils.data.DataLoader(datasets.CIFAR10(filepath, train=False, transform=CIFARtransform), batch_size=local_batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CNN Model Training with CIFAR-10 IID</h2>\n",
    "\n",
    "<t>Training is done using *'Random'* Scheduling</t>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training: Model - FedPAQ, Schedule - Random, Data Distribution - IID CIFAR-10 ===\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# CNN_FedAvg = CNN().to(device)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Training: Model - FedPAQ, Schedule - Random, Data Distribution - IID CIFAR-10 ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m FedPAQ_losses, FedPAQ_eval_losses, FedPAQ_accuracies \u001b[38;5;241m=\u001b[39m RNG_training(CNN, CNN_FedPAQ, lr, total_clients, clients_per_round, total_rounds, local_epochs, CIFAR10_training, CIFAR10_validation, quantization_level)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Save Final Models\u001b[39;00m\n\u001b[0;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(CNN_FedPAQ\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mModels\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCNN_FedPAQ.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[78], line 24\u001b[0m, in \u001b[0;36mRNG_training\u001b[1;34m(model_type, global_model, lr, total_clients, clients_per_round, total_rounds, local_epochs, training_loaders, validation_loader, quantization_level)\u001b[0m\n\u001b[0;32m     21\u001b[0m     client_losses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m client_update(clients[clients_idx[i]], opt[clients_idx[i]], training_loaders[clients_idx[i]], local_epochs)\n\u001b[0;32m     22\u001b[0m     selected_models\u001b[38;5;241m.\u001b[39mappend(clients[clients_idx[i]])\n\u001b[1;32m---> 24\u001b[0m global_aggregate(global_model, selected_models, quantization_level)\n\u001b[0;32m     26\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m client_losses \u001b[38;5;241m/\u001b[39m clients_per_round\n\u001b[0;32m     27\u001b[0m valid_loss , valid_accuracy \u001b[38;5;241m=\u001b[39m model_evaluation(global_model, validation_loader)\n",
      "Cell \u001b[1;32mIn[77], line 9\u001b[0m, in \u001b[0;36mglobal_aggregate\u001b[1;34m(global_model, client_models, quantization_level)\u001b[0m\n\u001b[0;32m      6\u001b[0m     model_diff \u001b[38;5;241m=\u001b[39m {k: client_model\u001b[38;5;241m.\u001b[39mstate_dict()[k] \u001b[38;5;241m-\u001b[39m global_dict[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m global_dict\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Quantize the difference using the low-precision quantizer\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     quantized_update \u001b[38;5;241m=\u001b[39m {k: QLP_i(model_diff[k], quantization_level) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m model_diff\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[0;32m     10\u001b[0m     quantized_updates\u001b[38;5;241m.\u001b[39mappend(quantized_update)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Aggregate the quantized updates and update the global model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[77], line 9\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m     model_diff \u001b[38;5;241m=\u001b[39m {k: client_model\u001b[38;5;241m.\u001b[39mstate_dict()[k] \u001b[38;5;241m-\u001b[39m global_dict[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m global_dict\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Quantize the difference using the low-precision quantizer\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     quantized_update \u001b[38;5;241m=\u001b[39m {k: QLP_i(model_diff[k], quantization_level) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m model_diff\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[0;32m     10\u001b[0m     quantized_updates\u001b[38;5;241m.\u001b[39mappend(quantized_update)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Aggregate the quantized updates and update the global model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[76], line 9\u001b[0m, in \u001b[0;36mQLP_i\u001b[1;34m(x, s)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Generate the random variable ξ_i(x, s)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(x) \u001b[38;5;241m/\u001b[39m (norm_x \u001b[38;5;241m*\u001b[39m s) \u001b[38;5;241m-\u001b[39m l\n\u001b[1;32m----> 9\u001b[0m xi \u001b[38;5;241m=\u001b[39m (l\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39ms \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m prob \u001b[38;5;28;01melse\u001b[39;00m l\u001b[38;5;241m/\u001b[39ms\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m norm_x \u001b[38;5;241m*\u001b[39m sign_x_i \u001b[38;5;241m*\u001b[39m xi\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "CNN_FedPAQ = CNN().to(device)\n",
    "# CNN_FedAvg = CNN().to(device)\n",
    "\n",
    "print(\"=== Training: Model - FedPAQ, Schedule - Random, Data Distribution - IID CIFAR-10 ===\")\n",
    "FedPAQ_losses, FedPAQ_eval_losses, FedPAQ_accuracies = RNG_training(CNN, CNN_FedPAQ, lr, total_clients, clients_per_round, total_rounds, local_epochs, CIFAR10_training, CIFAR10_validation, quantization_level)\n",
    "\n",
    "# Save Final Models\n",
    "torch.save(CNN_FedPAQ.state_dict(), '.\\\\Models\\\\CNN_FedPAQ.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>CNN Model Training/Inferencing Experience Comparison for CIFAR-10 IID</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'=================================== Final CNN Model Accuracies per Schedule ====================================')\n",
    "print(f'Random Scheduled FedPAQ CIFAR10 IID Model Accuracy: {FedPAQ_accuracies[-1]}')\n",
    "print(f'================================================================================================================')\n",
    "\n",
    "epochs_range = range(1, total_rounds + 1)\n",
    "\n",
    "# Plot Global Training Loss\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, FedPAQ_eval_losses, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.legend(loc='upper right')  \n",
    "plt.title('CNN CIFAR-10 IID Loss Curve')\n",
    "\n",
    "# Plot Global Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, FedPAQ_accuracies, color='red', linestyle=\"dashed\", label=\"Random Schedule\")\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.legend(loc='lower right') \n",
    "plt.title('CNN CIFAR-10 IID Accuracy Curve')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('.\\\\Plots\\\\cifar10_iid_FedPAQ_results.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
